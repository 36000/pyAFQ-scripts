{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hcp.recobundles/sub-2/sub-3_csd.nii.gz'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'hcp.recobundles' + f'/sub-{2}/sub-{3}_csd.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is already in place. If you want to fetch it again please first remove the folder /Users/john/AFQ_data/templates \n",
      "Dataset is already in place. If you want to fetch it again please first remove the folder /Users/john/AFQ_data/callosum_templates \n",
      "{'IFO_R', 'CGC_L', 'FP', 'ATR_L', 'UNC_L', 'FA', 'CST_R', 'HCC_R', 'SLF_L', 'CST_L', 'ILF_R', 'ILF_L', 'IFO_L', 'ATR_R', 'SLF_R', 'HCC_L', 'ARC_R', 'UNC_R', 'CGC_R', 'ARC_L'}\n"
     ]
    }
   ],
   "source": [
    "from AFQ.api import make_bundle_dict\n",
    "bundles_waypoint_roi = set(make_bundle_dict().keys())\n",
    "print(bundles_waypoint_roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is already in place. If you want to fetch it again please first remove the folder /Users/john/AFQ_data/hcp_atlas_16_bundles \n",
      "{'AF_L', 'F_R', 'CST_L', 'IFOF_R', 'F_L', 'UF_R', 'C_L', 'CST_R', 'UF_L', 'CCMid', 'MCP', 'whole_brain', 'CC_ForcepsMajor', 'CC_ForcepsMinor', 'AF_R', 'C_R', 'IFOF_L'}\n"
     ]
    }
   ],
   "source": [
    "from AFQ.data import read_hcp_atlas_16_bundles\n",
    "bundles_reco = set(read_hcp_atlas_16_bundles().keys())\n",
    "print(bundles_reco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CST_L', 'CST_R'}\n"
     ]
    }
   ],
   "source": [
    "print(bundles_waypoint_roi & bundles_reco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IFOF is IFO\n",
    "# UNC is UF\n",
    "# AF is ARC\n",
    "# CST is CST\n",
    "# FA and FP maybe related to F_L and F_R\n",
    "\n",
    "# F-1 score comparing set membership\n",
    "# dice coefficient between covered voxels (1 or 0 map)\n",
    "# compare bundle profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyAFQ examples. Performs tractography on HARDI dataset.\n",
    "\"\"\"\n",
    "==========================\n",
    "Plotting tract profiles\n",
    "==========================\n",
    "\n",
    "An example of tracking and segmenting two tracts, and plotting their tract\n",
    "profiles for FA (calculated with DTI).\n",
    "\n",
    "\"\"\"\n",
    "import os.path as op\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import dipy.data as dpd\n",
    "from dipy.data import fetcher\n",
    "import dipy.tracking.utils as dtu\n",
    "import dipy.tracking.streamline as dts\n",
    "from dipy.io.streamline import save_tractogram, load_tractogram\n",
    "from dipy.stats.analysis import afq_profile, gaussian_weights\n",
    "from dipy.io.stateful_tractogram import StatefulTractogram\n",
    "from dipy.io.stateful_tractogram import Space\n",
    "\n",
    "import AFQ.utils.streamlines as aus\n",
    "import AFQ.data as afd\n",
    "import AFQ.tractography as aft\n",
    "import AFQ.registration as reg\n",
    "import AFQ.dti as dti\n",
    "import AFQ.segmentation as seg\n",
    "from AFQ.utils.volume import patch_up_roi\n",
    "from AFQ.api import make_bundle_dict\n",
    "\n",
    "def \n",
    "print(f\"Fetching HCP subject {subject}\")\n",
    "afd.fetch_hcp([subject], \n",
    "              profile_name=False,\n",
    "              aws_access_key_id=hcp_ak,\n",
    "              aws_secret_access_key=hcp_sk)  \n",
    "dwi_dir = op.join(afd.afq_home, 'HCP', 'derivatives',\n",
    "                  'dmriprep', f'sub-{subject}', 'sess-01/dwi')\n",
    "\n",
    "hardi_fdata = op.join(dwi_dir, f\"sub-{subject}_dwi.nii.gz\")\n",
    "hardi_fbval = op.join(dwi_dir, f\"sub-{subject}_dwi.bval\")\n",
    "hardi_fbvec = op.join(dwi_dir, f\"sub-{subject}_dwi.bvec\")\n",
    "\n",
    "img = nib.load(hardi_fdata)\n",
    "\n",
    "print(\"Calculating DTI...\")\n",
    "if not op.exists(f'./{subject}/dti_FA.nii.gz'):\n",
    "    dti_params = dti.fit_dti(hardi_fdata, hardi_fbval, hardi_fbvec,\n",
    "                             out_dir=f'./{subject}')\n",
    "else:\n",
    "    dti_params = {'FA': f'./{subject}/dti_FA.nii.gz',\n",
    "                  'params': f'./{subject}/dti_params.nii.gz'}\n",
    "\n",
    "FA_img = nib.load(dti_params['FA'])\n",
    "FA_data = FA_img.get_fdata()\n",
    "\n",
    "templates = afd.read_templates()\n",
    "bundles = make_bundle_dict()\n",
    "\n",
    "print(\"Registering to template...\")\n",
    "MNI_T2_img = dpd.read_mni_template()\n",
    "if not op.exists(f'./{subject}/mapping.nii.gz'):\n",
    "    import dipy.core.gradients as dpg\n",
    "    gtab = dpg.gradient_table(hardi_fbval, hardi_fbvec)\n",
    "    warped_hardi, mapping = reg.syn_register_dwi(hardi_fdata, gtab)\n",
    "    reg.write_mapping(mapping, f'./{subject}/mapping.nii.gz')\n",
    "else:\n",
    "    mapping = reg.read_mapping(f'./{subject}/mapping.nii.gz', img, MNI_T2_img)\n",
    "\n",
    "\n",
    "print(\"Tracking...\")\n",
    "if not op.exists(f'./{subject}/dti_streamlines.trk'):\n",
    "    seed_roi = np.zeros(img.shape[:-1])\n",
    "    for name in bundle_names:\n",
    "        for hemi in ['_R', '_L']:\n",
    "            for roi in bundles[name + hemi]['ROIs']:\n",
    "                warped_roi = patch_up_roi(\n",
    "                    (mapping.transform_inverse(\n",
    "                        roi.get_data().astype(np.float32),\n",
    "                     interpolation='linear')) > 0)\n",
    "\n",
    "                # Add voxels that aren't there yet:\n",
    "                seed_roi = np.logical_or(seed_roi, warped_roi)\n",
    "\n",
    "    nib.save(nib.Nifti1Image(seed_roi.astype(float), img.affine), f'./{subject}/seed_roi.nii.gz')\n",
    "    streamlines = aft.track(dti_params['params'], #seed_mask=seed_roi,\n",
    "                            stop_mask=FA_data, stop_threshold=0.1)\n",
    "\n",
    "    sft = StatefulTractogram(streamlines, img, Space.RASMM)\n",
    "    save_tractogram(sft, f'./{subject}/dti_streamlines.trk',\n",
    "                    bbox_valid_check=False)\n",
    "else:\n",
    "    tg = load_tractogram(f'./{subject}/dti_streamlines.trk', img)\n",
    "    streamlines = tg.streamlines\n",
    "\n",
    "streamlines = dts.Streamlines(\n",
    "    dtu.transform_tracking_output(streamlines,\n",
    "                                  np.linalg.inv(img.affine)))\n",
    "\n",
    "print(\"Segmenting...\")\n",
    "segmentation_reco = seg.Segmentation(algo='reco',\n",
    "                                     model_clust_thr=20,\n",
    "                                     reduction_thr=20,\n",
    "                                     b0_threshold=50,\n",
    "                                     return_idx=True)\n",
    "bundle_names_reco = ['CST',\n",
    "                     'UF',\n",
    "                     'AF',\n",
    "                     'IFOF']\n",
    "bundle_names_reco = api.make_bundle_dict(bundle_names=bundle_names_reco, seg_algo='reco')\n",
    "fiber_groups_reco = segmentation_reco.segment(bundle_names_reco, streamlines, hardi_fdata, hardi_fbval, hardi_fbvec,\n",
    "                                              mapping=mapping, reg_template=MNI_T2_img)\n",
    "\n",
    "segmentation_afq = seg.Segmentation(algo='afq', return_idx=True)\n",
    "bundle_names_afq = ['CST',\n",
    "                    'UNC',\n",
    "                    'ARC',\n",
    "                    'IFO']\n",
    "bundle_names_afq = api.make_bundle_dict(bundle_names=bundle_names_afq, seg_algo='afq')\n",
    "fiber_groups_afq = segmentation_afq.segment(bundle_names_afq, streamlines, hardi_fdata, hardi_fbval, hardi_fbvec,\n",
    "                                            mapping=mapping, reg_template=MNI_T2_img)\n",
    "\n",
    "print(\"Cleaning...\")\n",
    "for kk in fiber_groups:\n",
    "    fiber_groups_reco[kk] = seg.clean_fiber_group(fiber_groups_reco[kk])\n",
    "    fiber_groups_afq[kk] = seg.clean_fiber_group(fiber_groups_afq[kk])\n",
    "    \n",
    "print(\"Extracting tract profiles...\")\n",
    "profiles = []\n",
    "for kk in fiber_groups_reco:\n",
    "    weights = gaussian_weights(fiber_groups_reco[kk])\n",
    "    profile = afq_profile(FA_data, fiber_groups_reco[kk],\n",
    "                          np.eye(4), weights=weights)\n",
    "    for ii in profile:\n",
    "        # Subject, Bundle, node, method, metric (FA, MD), value\n",
    "        profiles.append(subject, kk, ii, 'reco', 'FA', profile[ii])\n",
    "for kk in fiber_groups_afq:\n",
    "    weights = gaussian_weights(fiber_groups_afq[kk])\n",
    "    profile = afq_profile(FA_data, fiber_groups_afq[kk],\n",
    "                          np.eye(4), weights=weights)\n",
    "    for ii in profile:\n",
    "        # Subject, Bundle, node, method, metric (FA, MD), value\n",
    "        profiles.append(subject, kk, ii, 'afq', 'FA', profile[ii])\n",
    "\n",
    "profiles = pd.DataFrame(data=profiles, columns=[\"Subject\", \"Bundle\", \"Node\", \"Method\", \"Metric\", \"Value\"])\n",
    "profiles.to_csv(f\"./{subject}/profiles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
