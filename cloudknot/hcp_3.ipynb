{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os.path as op\n",
    "\n",
    "CP = configparser.ConfigParser()\n",
    "CP.read_file(open(op.join(op.expanduser('~'), '.aws', 'credentials')))\n",
    "CP.sections()\n",
    "aws_access_key = CP.get('hcp', 'AWS_ACCESS_KEY_ID')\n",
    "aws_secret_key = CP.get('hcp', 'AWS_SECRET_ACCESS_KEY')\n",
    "\n",
    "def attach_keys(arr):\n",
    "    return [(e, aws_access_key, aws_secret_key) for e in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_hcp(args):\n",
    "    import os.path as op\n",
    "    import numpy as np\n",
    "    import nibabel as nib\n",
    "    import dipy.data as dpd\n",
    "    from dipy.data import fetcher\n",
    "    import dipy.tracking.utils as dtu\n",
    "    import dipy.tracking.streamline as dts\n",
    "    from dipy.io.streamline import save_tractogram, load_tractogram\n",
    "    from dipy.stats.analysis import afq_profile, gaussian_weights\n",
    "    from dipy.io.stateful_tractogram import StatefulTractogram\n",
    "    from dipy.io.stateful_tractogram import Space\n",
    "    import dipy.core.gradients as dpg\n",
    "\n",
    "    import AFQ.utils.streamlines as aus\n",
    "    import AFQ.data as afd\n",
    "    import AFQ.tractography as aft\n",
    "    import AFQ.registration as reg\n",
    "    import AFQ.dti as dti\n",
    "    import AFQ.segmentation as seg\n",
    "    from AFQ.utils.volume import patch_up_roi\n",
    "    from AFQ.data import fetch_hcp\n",
    "\n",
    "    subject = args[0]\n",
    "    aws_access_key = args[1]\n",
    "    aws_secret_key = args[2]\n",
    "\n",
    "    data_paths = list(fetch_hcp([subject], profile_name=False,\n",
    "                                aws_access_key_id=aws_access_key,\n",
    "                                aws_secret_access_key=aws_secret_key).keys())\n",
    "    \n",
    "    fdata = data_paths[2]\n",
    "    fbval = data_paths[0]\n",
    "    fbvec = data_paths[1]\n",
    "\n",
    "    img = nib.load(fdata)\n",
    "    \n",
    "    dti_params = dti.fit_dti(fdata, fbval, fbvec,\n",
    "                             out_dir='.')\n",
    "    FA_img = nib.load(dti_params['FA'])\n",
    "    FA_data = FA_img.get_fdata()\n",
    "\n",
    "    templates = afd.read_templates()\n",
    "    bundle_names = [\"CST\", \"ILF\"]\n",
    "\n",
    "    bundles = {}\n",
    "    for name in bundle_names:\n",
    "        for hemi in ['_R', '_L']:\n",
    "            bundles[name + hemi] = {\n",
    "                'ROIs': [templates[name + '_roi1' + hemi],\n",
    "                         templates[name + '_roi2' + hemi]],\n",
    "                'rules': [True, True],\n",
    "                'prob_map': templates[name + hemi + '_prob_map'],\n",
    "                'cross_midline': False}\n",
    "\n",
    "    MNI_T2_img = dpd.read_mni_template()\n",
    "    gtab = dpg.gradient_table(fbval, fbvec)\n",
    "    _, mapping = reg.syn_register_dwi(fdata, gtab)\n",
    "\n",
    "    print(\"Tracking...\")\n",
    "    seed_roi = np.zeros(img.shape[:-1])\n",
    "    for name in bundle_names:\n",
    "        for hemi in ['_R', '_L']:\n",
    "            for roi in bundles[name + hemi]['ROIs']:\n",
    "                warped_roi = patch_up_roi(\n",
    "                    (mapping.transform_inverse(\n",
    "                        roi.get_data().astype(np.float32),\n",
    "                     interpolation='linear')) > 0)\n",
    "\n",
    "                # Add voxels that aren't there yet:\n",
    "                seed_roi = np.logical_or(seed_roi, warped_roi)\n",
    "\n",
    "    nib.save(nib.Nifti1Image(seed_roi.astype(float), img.affine), 'seed_roi.nii.gz')\n",
    "    streamlines = aft.track(dti_params['params'], seed_mask=seed_roi,\n",
    "                            stop_mask=FA_data, stop_threshold=0.1)\n",
    "\n",
    "    streamlines = dts.Streamlines(\n",
    "        dtu.transform_tracking_output(streamlines,\n",
    "                                      np.linalg.inv(img.affine)))\n",
    "\n",
    "    print(\"Segmenting fiber groups...\")\n",
    "    segmentation = seg.Segmentation()\n",
    "    segmentation.segment(bundles,\n",
    "                         streamlines,\n",
    "                         fdata=fdata,\n",
    "                         fbval=fbval,\n",
    "                         fbvec=fbvec,\n",
    "                         mapping=mapping,\n",
    "                         reg_template=MNI_T2_img)\n",
    "\n",
    "\n",
    "    fiber_groups = segmentation.fiber_groups\n",
    "\n",
    "    for bundle in bundles:\n",
    "        fiber_groups[bundle] = seg.clean_fiber_group(fiber_groups[bundle])\n",
    "\n",
    "    profiles = []\n",
    "    print(\"Extracting tract profiles...\")\n",
    "    for bundle in bundles:\n",
    "        weights = gaussian_weights(fiber_groups[bundle])\n",
    "        profile = afq_profile(FA_data, fiber_groups[bundle],\n",
    "                              np.eye(4), weights=weights)\n",
    "        profiles.append(profile)\n",
    "\n",
    "    return [bundles, profiles]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#profile_hcp([\"100206\", aws_access_key, aws_secret_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudknot as ck\n",
    "ck.set_region('us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "knot = ck.Knot(name='profile-hcp-3',\n",
    "               image_github_installs=(\"https://github.com/arokem/pyAFQ.git\"),\n",
    "               resource_type='SPOT',\n",
    "               bid_percentage=100,\n",
    "               memory=64000,\n",
    "               func=profile_hcp, pars_policies=('AmazonS3FullAccess',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_futures = knot.map(attach_keys([\"100206\", \"162228\", \"175540\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID              Name                        Status   \n",
      "---------------------------------------------------------\n",
      "d15a8177-1868-4a25-8744-002393f7e1ad        profile-hcp-3-0             SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "knot.view_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j0 = knot.jobs[0]\n",
    "print(len(j0.result()))\n",
    "bundles, profiles = j0.result()\n",
    "for bundle_idx, bundle in bundles:\n",
    "    fig, ax = plt.subplots(1)\n",
    "    \n",
    "    ax.plot(profiles[bundle_idx])\n",
    "    ax.set_title(bundle)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "knot.clobber(clobber_pars=True, clobber_repo=True, clobber_image=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
